{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyqF0gsMUinG",
        "outputId": "40a84fb0-0401-4ff0-e8c9-0a7130af6d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count:\n",
            "Hello: 2\n",
            "World: 1\n",
            "amazing: 1\n",
            "and: 1\n",
            "class: 1\n",
            "cs: 2\n",
            "forward: 1\n",
            "giveup: 1\n",
            "going: 1\n",
            "is: 1\n",
            "just: 1\n",
            "keep: 1\n",
            "look: 1\n",
            "never: 1\n",
            "study: 1\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"\n",
        "Hello cs Hello World\n",
        "cs is amazing class\n",
        "study and look forward never giveup\n",
        "just keep going\n",
        "\"\"\"\n",
        "\n",
        "# splitting the text into words and counting occurrences and that happen in map\n",
        "def mapper(text):\n",
        "    word_count = defaultdict(int)\n",
        "    # Split text into lines, then words\n",
        "    for line in text.strip().split(\"\\n\"):\n",
        "        words = line.split()\n",
        "        for word in words:\n",
        "            word_count[word] += 1\n",
        "    return word_count\n",
        "\n",
        "# aggregating the counts to sum the occurence of each word (token )\n",
        "def reducer(mapped_data):\n",
        "    reduced_data = defaultdict(int)\n",
        "    for word, count in mapped_data.items():\n",
        "        reduced_data[word] += count\n",
        "    return reduced_data\n",
        "\n",
        "# call function to work and give it parameters\n",
        "mapped_data = mapper(text)\n",
        "reduced_data = reducer(mapped_data)\n",
        "\n",
        "# Display the result\n",
        "print(\"Word Count:\")\n",
        "for word, count in sorted(reduced_data.items()):\n",
        "    print(f\"{word}: {count}\")\n"
      ]
    }
  ]
}